#!/usr/bin/env node

const fs = require('fs');
const readline = require('readline');

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout
});

console.log('\nüöÄ Codex AI Assistant - Environment Setup\n');
console.log('This will help you create your .env file.\n');

const questions = [
  {
    key: 'LLM_PROVIDER',
    question: 'Which LLM provider do you want to use?\n  1. OpenRouter (FREE models available)\n  2. OpenAI (requires credits)\nEnter 1 or 2: ',
    transform: (answer) => answer === '1' ? 'openrouter' : 'openai'
  },
  {
    key: 'SUPABASE_URL',
    question: 'Enter your Supabase URL: ',
    validate: (val) => val.startsWith('https://') || 'Must start with https://'
  },
  {
    key: 'SUPABASE_ANON_KEY',
    question: 'Enter your Supabase Anon Key: '
  },
  {
    key: 'SUPABASE_SERVICE_KEY',
    question: 'Enter your Supabase Service Role Key: '
  }
];

const conditionalQuestions = {
  openrouter: [
    {
      key: 'OPENROUTER_API_KEY',
      question: 'Enter your OpenRouter API Key (get free at https://openrouter.ai/keys): '
    },
    {
      key: 'OPENAI_MODEL',
      question: 'Which model? (press Enter for free model)\n  1. meta-llama/llama-3.2-3b-instruct:free (FREE)\n  2. google/gemma-2-9b-it:free (FREE)\n  3. Custom model name\nEnter choice or model name: ',
      transform: (answer) => {
        if (answer === '1' || answer === '') return 'meta-llama/llama-3.2-3b-instruct:free';
        if (answer === '2') return 'google/gemma-2-9b-it:free';
        return answer;
      }
    }
  ],
  openai: [
    {
      key: 'OPENAI_API_KEY',
      question: 'Enter your OpenAI API Key: '
    },
    {
      key: 'OPENAI_MODEL',
      question: 'Which model? (press Enter for gpt-4o-mini)\n  1. gpt-4o-mini (recommended)\n  2. gpt-3.5-turbo (cheaper)\n  3. gpt-4o (better quality)\n  4. Custom model name\nEnter choice or model name: ',
      transform: (answer) => {
        if (answer === '1' || answer === '') return 'gpt-4o-mini';
        if (answer === '2') return 'gpt-3.5-turbo';
        if (answer === '3') return 'gpt-4o';
        return answer;
      }
    }
  ]
};

const config = {
  PORT: '3000',
  NODE_ENV: 'development',
  JWT_SECRET: 'change_this_to_a_random_secret_' + Math.random().toString(36).substring(7),
  JWT_EXPIRES_IN: '7d',
  ALLOWED_ORIGINS: 'http://localhost:3001,http://localhost:19006',
  RATE_LIMIT_WINDOW_MS: '900000',
  RATE_LIMIT_MAX_REQUESTS: '100',
  LOG_LEVEL: 'info',
  APP_URL: 'http://localhost:3001'
};

async function askQuestion(question) {
  return new Promise((resolve) => {
    rl.question(question.question, (answer) => {
      if (question.validate) {
        const validation = question.validate(answer);
        if (validation !== true) {
          console.log(`‚ùå ${validation}`);
          return askQuestion(question).then(resolve);
        }
      }
      resolve(question.transform ? question.transform(answer) : answer);
    });
  });
}

async function setup() {
  try {
    // Ask main questions
    for (const question of questions) {
      config[question.key] = await askQuestion(question);
    }

    // Ask provider-specific questions
    const provider = config.LLM_PROVIDER;
    const providerQuestions = conditionalQuestions[provider] || [];
    
    for (const question of providerQuestions) {
      config[question.key] = await askQuestion(question);
    }

    // Generate .env content
    let envContent = '# Codex AI Assistant - Environment Configuration\n';
    envContent += '# Generated by setup script\n\n';
    
    envContent += '# Server Configuration\n';
    envContent += `PORT=${config.PORT}\n`;
    envContent += `NODE_ENV=${config.NODE_ENV}\n\n`;
    
    envContent += '# Supabase Configuration\n';
    envContent += `SUPABASE_URL=${config.SUPABASE_URL}\n`;
    envContent += `SUPABASE_ANON_KEY=${config.SUPABASE_ANON_KEY}\n`;
    envContent += `SUPABASE_SERVICE_KEY=${config.SUPABASE_SERVICE_KEY}\n\n`;
    
    envContent += '# LLM Provider Configuration\n';
    envContent += `LLM_PROVIDER=${config.LLM_PROVIDER}\n\n`;
    
    if (config.LLM_PROVIDER === 'openai') {
      envContent += '# OpenAI Configuration\n';
      envContent += `OPENAI_API_KEY=${config.OPENAI_API_KEY}\n`;
      envContent += `OPENAI_MODEL=${config.OPENAI_MODEL}\n\n`;
    } else {
      envContent += '# OpenRouter Configuration\n';
      envContent += `OPENROUTER_API_KEY=${config.OPENROUTER_API_KEY}\n`;
      envContent += `OPENAI_MODEL=${config.OPENAI_MODEL}\n`;
      envContent += `APP_URL=${config.APP_URL}\n\n`;
    }
    
    envContent += '# JWT Configuration\n';
    envContent += `JWT_SECRET=${config.JWT_SECRET}\n`;
    envContent += `JWT_EXPIRES_IN=${config.JWT_EXPIRES_IN}\n\n`;
    
    envContent += '# CORS Configuration\n';
    envContent += `ALLOWED_ORIGINS=${config.ALLOWED_ORIGINS}\n\n`;
    
    envContent += '# Rate Limiting\n';
    envContent += `RATE_LIMIT_WINDOW_MS=${config.RATE_LIMIT_WINDOW_MS}\n`;
    envContent += `RATE_LIMIT_MAX_REQUESTS=${config.RATE_LIMIT_MAX_REQUESTS}\n\n`;
    
    envContent += '# Logging\n';
    envContent += `LOG_LEVEL=${config.LOG_LEVEL}\n`;

    // Write .env file
    fs.writeFileSync('.env', envContent);
    
    console.log('\n‚úÖ .env file created successfully!\n');
    console.log('üìù Configuration:');
    console.log(`   Provider: ${config.LLM_PROVIDER}`);
    console.log(`   Model: ${config.OPENAI_MODEL}`);
    console.log(`   Supabase: ${config.SUPABASE_URL}\n`);
    console.log('üöÄ You can now run: npm run dev\n');
    
  } catch (error) {
    console.error('\n‚ùå Error:', error.message);
  } finally {
    rl.close();
  }
}

setup();
